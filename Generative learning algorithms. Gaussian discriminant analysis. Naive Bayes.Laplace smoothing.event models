# 生成学习算法

学习算法模型 $p(y|x;\theta)$ ，即给定 $x$ 的 $y$ 服从条件分布。例如，逻辑回归模型 $p(y|x;\theta)$ ，$h_\theta(x)=g(\theta^Tx)$ ，在这里$g$ 是$sigmoid$ 函数

考虑一个关于大象和狗的分类问题时，逻辑回归或感知器算法都是尝试找到一条直线来把两类分开，当有一个动物输入时，检查它是属于哪一边，然后预测它。

现在有一个不同的处理方法，首先，给大象建立一个模型，然后再迭代搜索狗，给狗建立一个模型。把新的动物与大像的模型和狗的模型进行匹配，来判断这个动物是大象还是狗。

直接学习$p(y|x)$ 的算法（逻辑回归）或直接学习$X$空间到标签{0,1}的映射算法（感知器算法）都被称为是判别学习算法。

**生成算法：**例如，y表示一个样本是狗（0）或大象（1），那么$p(x|y=0)$ 模型表示狗的特征分布，$p(x|y=1)$ 模型表示大象的特征分布。

在对$p(y)$ （类先验概率）建模和$p(x|y)$ ，我们的算法可以用贝斯叶规则来得到给定$x$ 的$y$ 的分布。

$$p(y|x)=\frac{p(x|y)p(y)}{p(x)}$$

$$p(x)=p(x|y=1)p(y=1)+p(x|y=0)p(y=0)$$

$p(x|y)$ 是在给定类型（y）的条件下，特征(x)的概论模型。

$$\begin{align}arg \max_y p(y|x)=arg \max_y\frac{p(x|y)p(y)}{p(x)}\\=arg \max_y p(x|y)p(y)\\\end{align}$$

求出使 $p(y|x)$ 最大的 $y$ ，因为 $x$ 相互独立，所以 $p(x)$ 不影响 $y$ 取值，可省略（注意，如果$y$ 就均匀分布，那么也可以省略 $p(y)$ ）

## 1 高斯判别分析

**高斯判别分析（GDA）：**假定 $p(x|y)$ 是多元正态分布。

### 1.1 多元正态分布

$n$ 维多元正态分布，也叫多元高斯分布，参数是一个**均值向量** $\mu\in \mathbb{R}^n$ 和**协方差矩阵** $\Sigma\in \mathbb{R}^{n\times n}$ ，在这里 $\Sigma\ge 0$ 是对称和positive semi-definite。也可以写成是“ $\mathcal{N}(\mu,\Sigma)$ ”，它的定义是：

$$p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))$$

$|\Sigma|$ 代表矩阵 $\Sigma$ 的行列式

对于随机变量 $X$ 服从分布 $\mathcal{N}(\mu,\Sigma)$ ，均值是给定 $\mu$ ：

$$E[X]=\int_{x}xp(x;\mu,\Sigma)dx=\mu$$

一个向量值随机变量$Z$的协方差用 $Cov(Z)=E[(Z-E[Z])(Z-E[Z])^T]$ 定义。也可以这样定义：

$$Cov(Z)=E[ZZ^T]-(E[Z])(E[Z])^T$$

如果$X\sim\mathcal{N}(\mu,\Sigma)$，那么：
$$Cov(X)=\Sigma$$

<img src="images/协方差高斯表现.png" style="width:700px;height:200px;">

$$\Sigma=\begin{bmatrix}1&0\\0&1\end{bmatrix};\Sigma=\begin{bmatrix}0.6&0\\0&0.6\end{bmatrix};\Sigma=\begin{bmatrix}2&0\\0&2\end{bmatrix};$$

左图是0均值和协方差 $\Sigma=I$ ($2\times2$ 标准矩阵)的高斯分布表现，也叫**标准正态分布**。中间的图是0均值和协方差 $\Sigma=0.6I$ 的高斯分布表现，右图是 $\Sigma=2I$ 。如果 $\Sigma$ 比较大，则图比较“偏平”，如果比较小，则图比较“突出”

<img src="images/协方差增加对角.png" style="width:700px;height:200px;">

上图中协方差分别为：
$$\Sigma=\begin{bmatrix}1&0\\0&1\end{bmatrix};\Sigma=\begin{bmatrix}1&0.5\\0.5&1\end{bmatrix};\Sigma=\begin{bmatrix}1&0.8\\0.8&1\end{bmatrix};$$

<img src="images/协方差二维图.png" style="width:700px;height:200px;">

<img src="images/协方差二维图1.png" style="width:700px;height:200px;">

$$\Sigma=\begin{bmatrix}1&-0.5\\-0.5&1\end{bmatrix};\Sigma=\begin{bmatrix}1&-0.8\\-0.8&1\end{bmatrix};\Sigma=\begin{bmatrix}3&0.8\\0.8&1\end{bmatrix};$$

保证 $\Sigma=I$ ，改变 $\mu$

<img src="images/均值向量.png" style="width:700px;height:200px;">

$$\mu = \begin{bmatrix}1\\0\end{bmatrix};\mu = \begin{bmatrix}-0.5\\0\end{bmatrix};\mu = \begin{bmatrix}-1\\-1.5\end{bmatrix};$$

### 1.2 高斯判别分析模型

处理分类问题时，如果输入特征 $x$是连续值随机变量，那么可以使用高斯判别分析（GDA）模型，该模型的 $p(x|y)$是多元正态分布。模型是：

 $$y\sim Bernoulli(\phi)\\x|y=0\sim \mathcal{N}(\mu_0,\Sigma)\\x|y=1\sim\mathcal{N}(\mu_1,\Sigma) $$

对应的分布公式：

 $$p(y)=\phi^y(1-\phi)^{1-y} $$

 $$p(x|y=0)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu_0)^T\Sigma^{-1}(x-\mu_0))$$

$$p(x|y=1)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu_1)^T\Sigma^{-1}(x-\mu_1))$$

在这里，模型参数是 $\phi,\Sigma,\mu_0和\mu_1$，两个均值和一个协方差 $\Sigma$。数据的对数似然函数：

$$\begin{align}\ell(\phi,\mu_0,\mu_1,\Sigma)=log\prod_{i=1}^m p(x^{(i)},y^{(i)};\phi,\mu_0,\mu_1,\Sigma)\\=log\prod_{i=1}^m p(x^{(i)}|y^{(i)};\mu_0,\mu_1,\Sigma)p(y^{(i)};\phi)\\\end{align}$$

要使 $\ell$最大化，需要依赖参数。我们发现参数的最大似然评价是：

$$\phi=\frac{1}{m}\sum_{i=1}^m 1\left\{y^{i}=1\right\}$$

$$\mu_0=\frac{\begin{matrix} \sum_{i=1}^m 1\left\{y^{i}=0\right\}x^{(i)}\end{matrix}}{\begin{matrix} \sum_{i=1}^m 1\left\{y^{i}=0\right\}\end{matrix}}$$

$$\mu_0=\frac{\begin{matrix} \sum_{i=1}^m 1\left\{y^{i}=1\right\}x^{(i)}\end{matrix}}{\begin{matrix} \sum_{i=1}^m 1\left\{y^{i}=1\right\}\end{matrix}}$$

$$\Sigma=\frac{1}{m}\sum_{i=1}^m (x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$$

对应的算法绘图如下：
<img src="images/生成学习算法线.png" style="width:500px;height:500px;">

最后，结合公式：

$$p(y|x)=\frac{p(x|y)p(y)}{p(x)}$$

$$p(x)=p(x|y=1)p(y=1)+p(x|y=0)p(y=0)$$

可得到 $p(y|x)$
